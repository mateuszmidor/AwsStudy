@startmindmap 00-diagram

title AWS Serverless

<style>
mindmapDiagram {
  .vpc {
    BackgroundColor Pink
  }
  .orange {
    BackgroundColor orange
  }
  .invocation {
    BackgroundColor LightSkyBlue
  }
  .performance {
    BackgroundColor LightGreen
  }
  .concurrency {
    BackgroundColor LightSalmon
  }
  .cf {
    BackgroundColor LightSteelBlue
  }
  .versions {
    BackgroundColor LightSeaGreen
  }
}
</style>


*[#Orange] <b>Lambda
 * <b>Invocation:\n*Synchronous\n**CLI, SDK\n**API Gateway\n**Application Load Balancer\n**Lambda@Edge - CloudFront\n*Asynchronous <<invocation>>
  * <b>Asynchronous Lambda\n*S3, SNS, CloudWatch Events, ...\n*events are placed on internal queue\n*2x retry on error: after 1 and 2 minutes\n*can process message twice - ensure func is idempotent\n*can define Dead Letter Queue for failed reattempts <<invocation>>
   * <b>EventBridge\n*CRON or Fixed Rate Event Bridge Rule\n**eg. run lambda every minute\n*CodePipeline Event Bridge Rule\n**eg. detect CodePipeline state changes <<invocation>>
   * <b>S3 notifications\n*eg. run lambda on S3 file upload <<invocation>>
  * <b>Event Source Mapping (Synchronous)\n*a way to automatically run lambda\nwhen records appear in the source\n*records are POLLED from the source,\nthen lambda is run with event batch\n*lambda needs permission\nto read the event data from source\n*event sources:\n**Kinesis Data Streams\n**DynamoDB Streams\n**SQS queues <<invocation>>
   * <b>Streams\n*iterator is created for each shard, process items in order\n*processed items are not removed from the stream\n*on error:\n**by default entire batch is reprocessed until success\nor items in batch expire; this can block your processing!\n**can discard old events\n**can limit number of retries\n**can split the batch (workaround for Lambda timeout issue)\n**discarded events can go to Destination <<invocation>>
   * <b>Queues\n*use Long polling with batches 1-10 messages\n*setup DeadLetterQueue with your SQS, not with Lambda;\n DLQ works only with async lambda calls and here is sync calls\n*message may be processed twice even when no error,\n so better ensure idempotency\n*processed messages are deleted from the queue <<invocation>>
 * <b>Lambda with Applicatin Load Balancer\n*HTTP request gets to ALB\n*ALB converts HTTP request -> JSON\n*and forwards JSON to EC2 Target Group\n*which returns JSON->HTTP Response->Client\n*Target Group can enable multi-header values\n*conversion of multi-header values:\n**?name=foo&name=bar -> name:[foo, bar]
 * <b>Lambda@Edge\n*synchronous invocation\n*modify CloudFront(CDN) requests&responses
 * <b>Destinations\n*to store result/error of async operation somewhere\n*support for SQS, SNS, Lambda, EventBridge bus\n*in case of Lambda - first happen 2 auto retries\n*can be used to replace DeadLetter queue in SQS
 * <b>Execution role\n*allow Lambda function to interact with other resource
 * <b>Resource-based policy\n*allow other resource/account\nto run Lambda function 
 * <b>VPC\n*by default Lambda runs in dedicated VPC\n outside your own VPC and so it  can't\n access your other resources eg. DynamoDB\n*the solution is to deploy Lambda in your VPC <<vpc>>
  * <b>Lambda in your VPC\n*define VPC ID, Subnets and Security Groups\n*Lambda will create Elastic Network Interface\n (ENI) in your subnets\n*through the ENI Lambda will access the private subnets\n*needs: AWSLambdaVPCAccessExecutionRole\n*by default, such deployment doesn't give your lambda\n internet access nor public IP\n**even if deployed in Public Subnet!\n*the solution is to use NAT Gateway or NAT Instance\n*to just access other services it's enough to use VPC Endpoints\n**VPC Endpoints are defined per-service in the VPC\n**they add an entry in Route Table\n*CloudWatch Logs will work ALWAYS no matter what :) <<vpc>>
 * <b>Lambda performance\n*128MB to 10GB RAM, 1MB increments\n*vCPUs allocated automatically:\n get  s 1vCPU for each requested 1792MB RAM\n*timeout: default 3sec, max 900sec <<performance>>
  * <b>Execution Context\n*initialized with first Lambda invocation\n*includes /tmp directory - 512 MB storage\n**for permanent storage - use S3\n*preserved across Lambda invocations\n*used to reuse once initialized environment, eg\n database connections, http clients, precomputed data\n*global variables are stored in     Execution Context\n*it is NOT the: ""def lambda_handler(event, **context**):"" <<performance>>
 * <b>Lambda Concurrency\n*max of 1000 concurrent executions across entire account\n*but should set limit for each Function; otherwise other apps\n in the account may get throttled eg. on black friday :) \n*can increase through support ticket <<concurrency>>
  * <b>Throttling\n*synchronous invocation - return HTTP 429\n*async invocation - auto-retry, then go to Dead Letter Queue\n eg. S3 event notifications, with exponential backoff <<concurrency>>
  * <b>Cold starts & Provisioned concurrency\n*cold start = first user needs to wait for execution context init\n*provisioned concurrency = pool of initialized contexts <<concurrency>>
 * <b>Lambda dependencies\n*need to ZIP dependencies folder together with function code:\n**pip --target options\n**go mod vendor\n*upload ZIP to Lambda if less than 50MB,\n otherwise to S3 first and then reference them from Lambda
 * <b>Lambda over CloudFormation\n*it is possible create Lambda using CloudFormation <<cf>>
  * inline - as embedded code in CloudFormation config file,\n can't include dependencies this way <<cf>>
  * using S3 - reference S3 ZIP from CloudFormation,\n use ObjectVersioning so CloudFormation automatically\n detects and deploys the change!  <<cf>>
 * <b>Lambda Layers\n*create custom runtimes, eg C++, Rust\n*externalize dependencies to reuse them and avoid\n packaging heavy dependencies along with code
 * <b>Lambda Containers\n*Lambda can run container up to 10GB from ECR\n*you just create the function from container instead of from scratch or blueprint\n*pack large and complex dependencies into container\n*base images available for Python, Node, Go, Java, Ruby\n*can build custom image implementing Lambda Runtime\n*test containers using Lambda Runtime Interface Emulator\n*can be alternative to Lambda Layers
 * <b>Lambda versions and aliases <<versions>>
  * <b>Versions\n*each Deploy creates new, immutable version\n*version = code + configuration<<versions>>
  * <b>Aliases\n*alias is a pointer to specific Lambda version\n**eg. "$Latest"\n*can point to 2 versions with weights\n**this enables Blue\Green deployments by routing X% of traffic to given aliases\n*alias gets it's own ARN\n*alias can't reference other alias\n*alias is mutable - can be updated to point to a different version<<versions>>
 * <b>Lambda and CodeDeploy\n*CodeDeploy can upgrade lambda to a new version. Strategies:\n**Linear10PercentEvery3Minutes - smooth transition, switch additional 10% every 3 minutes\n**Linear10PercentEvery10Minutes\n**Canary10Percent5Munutes - try 10% for 5 minutes, then switch all traffic to new version\n**Canary10Percent30Munutes\n**AllAtOnce - just switch all traffic to new version immediately
 * <b>Lambda limits\n*limits are per-region\n*RAM: configurable 128MB - 10GB, more memory->more vcpus\n*max execution time: 15minutes\n*environment variables: total of 4KB data\n*/tmp folder: 512MB (part of execution environment)\n*concurrent executions: 1000\n*max compressed deployment ZIP: 50MB\n*max uncompressed deployment: 250MB
@endmindmap
